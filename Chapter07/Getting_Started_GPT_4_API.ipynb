{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Monday, March 18, 2024\n",
        "\n",
        "mamba activate t4nlpacv\n",
        "\n",
        "This all runs in one pass. This notebook makes numerous calls to OpenAI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPM-W5IVxfJS"
      },
      "source": [
        "# Getting Started with GPT-4 API\n",
        "\n",
        "copyright 2024 Denis Rothman\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1yf-ju9P62Zb"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image     #This is used for rendering images in the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7HO_zOAaA-Y"
      },
      "source": [
        "## Step 1: Installing & importing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdfE-07V_jzx"
      },
      "outputs": [],
      "source": [
        "# !pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8Uzj4_w_lea"
      },
      "outputs": [],
      "source": [
        "# !pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS_Qk62FxclT"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#   import openai\n",
        "# except:\n",
        "#   !pip install openai\n",
        "#   import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKbbxVMaYqy"
      },
      "source": [
        "## Step 2: Entering the API KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21LhKHnrxA5l"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8cmujpyxKjj"
      },
      "outputs": [],
      "source": [
        "# f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "# API_KEY=f.readline()\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTD5NZ4Ox-G4"
      },
      "source": [
        "Authentification\n",
        "\n",
        "Setting the environment variable OPENAI_API_KEY to the value of API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAzxa-GRx8Ip"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "OPENAI_API_KEY_ = os.environ['OPENAI_API_KEY_'] \n",
        "openai.api_key = OPENAI_API_KEY_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6d0bggZX_dw"
      },
      "source": [
        "## Step 3: Running an NLP tasks with the default parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKwqIwACcB2B"
      },
      "source": [
        "## Step 4: Example 1: Grammar correction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pkZrsEzzNwS",
        "outputId": "e6dde8a3-affe-471f-9e01-bb2c58409242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "She didn't go to the market.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with statements, and your task is to convert them to standard English.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"She no went to the market.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1AuRliZVfS"
      },
      "source": [
        "## Example 2: Translation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlRVPjEMBBI2",
        "outputId": "77bf4b9b-bc13-42b9-cf3f-6634d955e9fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elle n'est pas all√©e au march√©.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with sentences, and your task translate from English into French.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"She did not go to the market.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMUpe35ZA-t"
      },
      "source": [
        "## Example 3: Time Complexity\n",
        "\n",
        "https://platform.openai.com/examples/default-time-complexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jYE2kxxQocx",
        "outputId": "dbd8446e-27e0-479d-e1fa-01cced458a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time complexity of the provided Python code is O(n*k). \n",
            "\n",
            "This is because there are two nested loops in the code. The outer loop runs 'n' times and the inner loop runs 'k' times. Therefore, in the worst-case scenario, the statement inside the inner loop is executed 'n*k' times. Hence, the time complexity is O(n*k).\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with Python code, and your task is to calculate its time complexity.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"def foo(n, k):\\n        accum = 0\\n        for i in range(n):\\n            for l in range(k):\\n                accum += i\\n        return accum\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWGCjioUawKp"
      },
      "source": [
        "## Example 4: Text to emoji\n",
        "\n",
        "https://platform.openai.com/examples/default-emoji-translation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S7qedUIR7Mb",
        "outputId": "de311cc6-4c9d-4e7a-f952-e4da1caa96cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñüí°üî¨‚öôÔ∏èüìàüåêüåüü§û\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with text, and your task is to translate it into emojis. Do not use any regular text. Do your best with emojis only.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Artificial intelligence is a technology with great promise.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.8,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrS3kT-ebaT9"
      },
      "source": [
        "## Example 5: Spreadsheet creator\n",
        "\n",
        "https://platform.openai.com/examples/default-spreadsheet-gen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3yGaCEdR49a",
        "outputId": "10477644-054d-4873-e16b-a6955dcda326"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie,Year of Release\n",
            "\"Star Wars: Episode IV - A New Hope\",1977\n",
            "\"Blade Runner\",1982\n",
            "\"The Matrix\",1999\n",
            "\"Inception\",2010\n",
            "\"Star Trek\",2009\n",
            "\"Interstellar\",2014\n",
            "\"Avatar\",2009\n",
            "\"2001: A Space Odyssey\",1968\n",
            "\"E.T. the Extra-Terrestrial\",1982\n",
            "\"Star Wars: Episode V - The Empire Strikes Back\",1980\n",
            "\"Close Encounters of the Third Kind\",1977\n",
            "\"Star Wars: Episode VI - Return of the Jedi\",1983\n",
            "\"Jurassic Park\",1993\n",
            "\"The Day the Earth Stood Still\",1951\n",
            "\"The War of the Worlds\",1953\n",
            "\"Mad Max: Fury Road\",2015\n",
            "\"Star Wars: Episode VII - The Force Awakens\",2015\n",
            "\"The Fifth Element\",1997\n",
            "\"Terminator 2: Judgment Day\",1991\n",
            "\"Back to the Future\",1985\n",
            "\"The Time Machine\",1960\n",
            "\"Planet of the Apes\",1968\n",
            "\"Alien\",1979\n",
            "\"Gravity\",2013\n",
            "\"The Martian\",2015\n",
            "\"Guardians of the Galaxy\",2014\n",
            "\"Ex Machina\",2014\n",
            "\"Arrival\",2016\n",
            "\"Blade Runner 2049\",2017\n",
            "\"Ready Player One\",2018\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Create a two-column CSV of top science fiction movies along with the year of release.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.5,\n",
        "  max_tokens=300,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNY5uUu6ead0"
      },
      "source": [
        "## Example 6: Advanced Tweet classifier\n",
        "\n",
        "https://beta.openai.com/examples/default-tweet-classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDeD3FkbearQ",
        "outputId": "77872ddb-b132-45b9-c18b-2b67e819a26d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"I loved the new Batman movie!\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-Qiw1mjcmd6"
      },
      "source": [
        "## Example 7: Natural Language to SQL\n",
        "\n",
        "https://platform.openai.com/examples/default-sql-translate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qALmluVsWEnn",
        "outputId": "b5dc87e5-e91c-475e-accd-649fa8f6f7f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To compute the average total order value for all orders on 2023-04-01, we need to join the Orders, OrderDetails, and Products tables. We will sum the product of Quantity and UnitPrice for each order, and then compute the average of these sums.\n",
            "\n",
            "Here is the SQL query:\n",
            "\n",
            "    SELECT AVG(TotalOrderValue) AS AverageOrderValue\n",
            "    FROM (\n",
            "        SELECT Orders.OrderID, SUM(OrderDetails.Quantity * Products.UnitPrice) AS TotalOrderValue\n",
            "        FROM Orders\n",
            "        JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID\n",
            "        JOIN Products ON OrderDetails.ProductID = Products.ProductID\n",
            "        WHERE Orders.OrderDate = '2023-04-01'\n",
            "        GROUP BY Orders.OrderID\n",
            "    ) AS OrderValues;\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Given the following SQL tables, your job is to write queries given a user‚Äôs request.\\n    \\n    CREATE TABLE Orders (\\n      OrderID int,\\n      CustomerID int,\\n      OrderDate datetime,\\n      OrderTime varchar(8),\\n      PRIMARY KEY (OrderID)\\n    );\\n    \\n    CREATE TABLE OrderDetails (\\n      OrderDetailID int,\\n      OrderID int,\\n      ProductID int,\\n      Quantity int,\\n      PRIMARY KEY (OrderDetailID)\\n    );\\n    \\n    CREATE TABLE Products (\\n      ProductID int,\\n      ProductName varchar(50),\\n      Category varchar(50),\\n      UnitPrice decimal(10, 2),\\n      Stock int,\\n      PRIMARY KEY (ProductID)\\n    );\\n    \\n    CREATE TABLE Customers (\\n      CustomerID int,\\n      FirstName varchar(50),\\n      LastName varchar(50),\\n      Email varchar(100),\\n      Phone varchar(20),\\n      PRIMARY KEY (CustomerID)\\n    );\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Write a SQL query which computes the average total order value for all orders on 2023-04-01.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
